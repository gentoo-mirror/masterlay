From 4586b4ac174080ee3665a6c97998e91d20702a7a Mon Sep 17 00:00:00 2001
From: davilizh <davili@nvidia.com>
Date: Tue, 20 Jun 2017 18:19:41 +0800
Subject: [PATCH 1/2] The code is optimized for GTX1060, can improve GTX1060
 with 2 GPC performance by 15%, and GTX1060 with 1 GPC performance by more
 than 30%. Meanwhile, it also increases performance on GTX1070 by 3%, on
 Telsla M60 by 2%, and should also benefit other chips. However, also find 5%
 decrease for Nvidia GRID K520.

---
 dagger_shuffled.cuh         |  94 ++++++
 ethash_cuda_miner_kernel.cu | 155 +++++++++
 keccak.cuh                  | 787 ++++++++++++++++++++++++++++++++++++++++++++
 3 files changed, 1036 insertions(+)
 create mode 100644 dagger_shuffled.cuh
 create mode 100644 ethash_cuda_miner_kernel.cu
 create mode 100644 keccak.cuh

diff --git a/dagger_shuffled.cuh b/dagger_shuffled.cuh
new file mode 100644
index 0000000000..9d5754585a
--- /dev/null
+++ b/dagger_shuffled.cuh
@@ -0,0 +1,94 @@
+#include "ethash_cuda_miner_kernel_globals.h"
+#include "ethash_cuda_miner_kernel.h"
+#include "cuda_helper.h"
+
+#define PARALLEL_HASH 4
+
+__device__ uint64_t compute_hash(
+	uint64_t nonce
+	)
+{
+	// sha3_512(header .. nonce)
+	uint2 state[12];
+	
+	state[4] = vectorize(nonce);
+
+	keccak_f1600_init(state);
+	
+	// Threads work together in this phase in groups of 8.
+	const int thread_id  = threadIdx.x &  (THREADS_PER_HASH - 1);
+	const int mix_idx    = thread_id & 3;
+
+	for (int i = 0; i < THREADS_PER_HASH; i += PARALLEL_HASH)
+	{
+		uint4 mix[PARALLEL_HASH];
+		uint32_t offset[PARALLEL_HASH];
+		uint32_t init0[PARALLEL_HASH];
+	
+		// share init among threads
+		for (int p = 0; p < PARALLEL_HASH; p++)
+		{
+			uint2 shuffle[8];
+			for (int j = 0; j < 8; j++) 
+			{
+				shuffle[j].x = __shfl(state[j].x, i+p, THREADS_PER_HASH);
+				shuffle[j].y = __shfl(state[j].y, i+p, THREADS_PER_HASH);
+			}
+			switch (mix_idx)
+			{
+				case 0: mix[p] = vectorize2(shuffle[0], shuffle[1]); break;
+				case 1: mix[p] = vectorize2(shuffle[2], shuffle[3]); break;
+				case 2: mix[p] = vectorize2(shuffle[4], shuffle[5]); break;
+				case 3: mix[p] = vectorize2(shuffle[6], shuffle[7]); break;
+			}
+			init0[p] = __shfl(shuffle[0].x, 0, THREADS_PER_HASH);
+		}
+
+		for (uint32_t a = 0; a < ACCESSES; a += 4)
+		{
+			int t = bfe(a, 2u, 3u);
+
+			for (uint32_t b = 0; b < 4; b++)
+			{
+				for (int p = 0; p < PARALLEL_HASH; p++)
+				{
+					offset[p] = fnv(init0[p] ^ (a + b), ((uint32_t *)&mix[p])[b]) % d_dag_size;
+					offset[p] = __shfl(offset[p], t, THREADS_PER_HASH);
+				}
+				#pragma unroll
+				for (int p = 0; p < PARALLEL_HASH; p++)
+				{
+					mix[p] = fnv4(mix[p], d_dag[offset[p]].uint4s[thread_id]);
+				}
+			}
+		}
+
+		for (int p = 0; p < PARALLEL_HASH; p++)
+		{
+			uint2 shuffle[4];
+			uint32_t thread_mix = fnv_reduce(mix[p]);
+
+			// update mix accross threads
+
+			shuffle[0].x = __shfl(thread_mix, 0, THREADS_PER_HASH);
+			shuffle[0].y = __shfl(thread_mix, 1, THREADS_PER_HASH);
+			shuffle[1].x = __shfl(thread_mix, 2, THREADS_PER_HASH);
+			shuffle[1].y = __shfl(thread_mix, 3, THREADS_PER_HASH);
+			shuffle[2].x = __shfl(thread_mix, 4, THREADS_PER_HASH);
+			shuffle[2].y = __shfl(thread_mix, 5, THREADS_PER_HASH);
+			shuffle[3].x = __shfl(thread_mix, 6, THREADS_PER_HASH);
+			shuffle[3].y = __shfl(thread_mix, 7, THREADS_PER_HASH);
+
+			if ((i+p) == thread_id) {
+				//move mix into state:
+				state[8] = shuffle[0];
+				state[9] = shuffle[1];
+				state[10] = shuffle[2];
+				state[11] = shuffle[3];
+			}
+		}
+	}
+	
+	// keccak_256(keccak_512(header..nonce) .. mix);
+	return keccak_f1600_final(state);
+}
diff --git a/ethash_cuda_miner_kernel.cu b/ethash_cuda_miner_kernel.cu
new file mode 100644
index 0000000000..ac607c3a20
--- /dev/null
+++ b/ethash_cuda_miner_kernel.cu
@@ -0,0 +1,155 @@
+/*
+* Genoil's CUDA mining kernel for Ethereum
+* based on Tim Hughes' opencl kernel.
+* thanks to sp_, trpuvot, djm34, cbuchner for things i took from ccminer.
+*/
+
+#include "ethash_cuda_miner_kernel.h"
+#include "ethash_cuda_miner_kernel_globals.h"
+#include "cuda_helper.h"
+
+#include "fnv.cuh"
+
+#define copy(dst, src, count) for (int i = 0; i != count; ++i) { (dst)[i] = (src)[i]; }
+
+
+#if __CUDA_ARCH__ < SHUFFLE_MIN_VER
+#include "keccak_u64.cuh"
+#include "dagger_shared.cuh"
+#else
+#include "keccak.cuh"
+#include "dagger_shuffled.cuh"
+#endif
+
+__global__ void 
+ethash_search(
+	volatile uint32_t* g_output,
+	uint64_t start_nonce
+	)
+{
+	uint32_t const gid = blockIdx.x * blockDim.x + threadIdx.x;	
+	uint64_t hash = compute_hash(start_nonce + gid);
+	if (cuda_swab64(hash) > d_target) return;
+	uint32_t index = atomicInc(const_cast<uint32_t*>(g_output), SEARCH_RESULT_BUFFER_SIZE - 1) + 1;
+	g_output[index] = gid;
+}
+
+void run_ethash_search(
+	uint32_t blocks,
+	uint32_t threads,
+	uint32_t sharedbytes,
+	cudaStream_t stream,
+	volatile uint32_t* g_output,
+	uint64_t start_nonce
+)
+{
+	ethash_search << <blocks, threads, sharedbytes, stream >> >(g_output, start_nonce);
+	CUDA_SAFE_CALL(cudaGetLastError());
+}
+
+#define ETHASH_DATASET_PARENTS 256
+#define NODE_WORDS (64/4)
+
+__global__ void
+ethash_calculate_dag_item(uint32_t start)
+{
+	uint32_t const node_index = start + blockIdx.x * blockDim.x + threadIdx.x;
+	if (node_index > d_dag_size * 2) return;
+
+	hash200_t dag_node;
+	copy(dag_node.uint4s, d_light[node_index % d_light_size].uint4s, 4);
+	dag_node.words[0] ^= node_index;
+	SHA3_512(dag_node.uint2s);
+
+	const int thread_id = threadIdx.x & 3;
+
+	for (uint32_t i = 0; i != ETHASH_DATASET_PARENTS; ++i) {
+		uint32_t parent_index = fnv(node_index ^ i, dag_node.words[i % NODE_WORDS]) % d_light_size;
+#if __CUDA_ARCH__ < SHUFFLE_MIN_VER
+		for (unsigned w = 0; w != 4; ++w) {
+			dag_node.uint4s[w] = fnv4(dag_node.uint4s[w], d_light[parent_index].uint4s[w]);
+		}
+#else
+		for (uint32_t t = 0; t < 4; t++) {
+			uint32_t shuffle_index = __shfl(parent_index, t, 4);
+			uint4 p4 = d_light[shuffle_index].uint4s[thread_id];
+
+			for (int w = 0; w < 4; w++) {
+				uint4 s4 = make_uint4(__shfl(p4.x, w, 4), __shfl(p4.y, w, 4), __shfl(p4.z, w, 4), __shfl(p4.w, w, 4));
+				if (t == thread_id) {
+					dag_node.uint4s[w] = fnv4(dag_node.uint4s[w], s4);
+				}
+			}
+
+		}
+#endif		
+	}
+	SHA3_512(dag_node.uint2s);
+	hash64_t * dag_nodes = (hash64_t *)d_dag;
+
+#if __CUDA_ARCH__ < SHUFFLE_MIN_VER
+	for (uint32_t i = 0; i < 4; i++) {
+		dag_nodes[node_index].uint4s[i] =  dag_node.uint4s[i];
+	}
+#else
+	for (uint32_t t = 0; t < 4; t++) {
+
+		uint32_t shuffle_index = __shfl(node_index, t, 4);
+		uint4 s[4];
+		for (uint32_t w = 0; w < 4; w++) {
+			s[w] = make_uint4(__shfl(dag_node.uint4s[w].x, t, 4), __shfl(dag_node.uint4s[w].y, t, 4), __shfl(dag_node.uint4s[w].z, t, 4), __shfl(dag_node.uint4s[w].w, t, 4));
+		}
+		dag_nodes[shuffle_index].uint4s[thread_id] = s[thread_id];
+	}
+#endif		 
+}
+
+void ethash_generate_dag(
+	uint64_t dag_size,
+	uint32_t blocks,
+	uint32_t threads,
+	cudaStream_t stream,
+	int device
+	)
+{
+	uint32_t const work = (uint32_t)(dag_size / sizeof(hash64_t));
+
+	uint32_t fullRuns = work / (blocks * threads);
+	uint32_t const restWork = work % (blocks * threads);
+	if (restWork > 0) fullRuns++;
+	for (uint32_t i = 0; i < fullRuns; i++)
+	{
+		ethash_calculate_dag_item <<<blocks, threads, 0, stream >>>(i * blocks * threads);
+		CUDA_SAFE_CALL(cudaDeviceSynchronize());
+		printf("CUDA#%d: %.0f%%\n",device, 100.0f * (float)i / (float)fullRuns);
+	}
+	//printf("GPU#%d 100%%\n");
+	CUDA_SAFE_CALL(cudaGetLastError());
+}
+
+void set_constants(
+	hash128_t* _dag,
+	uint32_t _dag_size,
+	hash64_t * _light,
+	uint32_t _light_size
+	)
+{
+	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_dag, &_dag, sizeof(hash128_t *)));
+	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_dag_size, &_dag_size, sizeof(uint32_t)));
+	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_light, &_light, sizeof(hash64_t *)));
+	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_light_size, &_light_size, sizeof(uint32_t)));
+}
+
+void set_header(
+	hash32_t _header
+	)
+{
+	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_header, &_header, sizeof(hash32_t)));
+}
+
+void set_target(
+	uint64_t _target
+	)
+{
+	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_target, &_target, sizeof(uint64_t)));
+}
diff --git a/keccak.cuh b/keccak.cuh
new file mode 100644
index 0000000000..ede8ecf54e
--- /dev/null
+++ b/keccak.cuh
@@ -0,0 +1,787 @@
+#include "cuda_helper.h"
+
+__device__ __constant__ uint64_t const keccak_round_constants[24] = {
+	0x0000000000000001ULL, 0x0000000000008082ULL, 0x800000000000808AULL,
+	0x8000000080008000ULL, 0x000000000000808BULL, 0x0000000080000001ULL,
+	0x8000000080008081ULL, 0x8000000000008009ULL, 0x000000000000008AULL,
+	0x0000000000000088ULL, 0x0000000080008009ULL, 0x000000008000000AULL,
+	0x000000008000808BULL, 0x800000000000008BULL, 0x8000000000008089ULL,
+	0x8000000000008003ULL, 0x8000000000008002ULL, 0x8000000000000080ULL,
+	0x000000000000800AULL, 0x800000008000000AULL, 0x8000000080008081ULL,
+	0x8000000000008080ULL, 0x0000000080000001ULL, 0x8000000080008008ULL
+};
+
+__device__ __forceinline__
+uint2 xor5(const uint2 a, const uint2 b, const uint2 c, const uint2 d, const uint2 e) {
+	return a ^ b ^ c ^ d ^ e;
+}
+__device__ __forceinline__
+uint2 xor3(const uint2 a, const uint2 b, const uint2 c) {
+	return a ^ b ^ c;
+}
+
+__device__ __forceinline__
+uint2 chi(const uint2 a, const uint2 b, const uint2 c) {
+	return a ^ (~b) & c;
+}
+
+__device__ __forceinline__ void keccak_f1600_init(uint2* state)
+{
+	uint2 s[25];
+	uint2 t[5], u, v;
+
+	s[4] = state[4];
+
+	devectorize2(d_header.uint4s[0], s[0], s[1]);
+	devectorize2(d_header.uint4s[1], s[2], s[3]);
+
+	for (uint32_t i = 5; i < 25; i++)
+	{
+		s[i] = make_uint2(0, 0);
+	}
+	s[5].x = 1;
+	s[8].y = 0x80000000;
+
+	/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
+	t[0].x = s[0].x ^ s[5].x;
+	t[0].y = s[0].y;
+	t[1] = s[1];
+	t[2] = s[2];
+	t[3].x = s[3].x;
+	t[3].y = s[3].y ^ s[8].y;
+	t[4] = s[4];
+
+	/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
+	/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
+
+	u = ROL2(t[1], 1);
+	s[0] = xor3(s[0], t[4], u);
+	s[5] = xor3(s[5], t[4], u);
+	s[10] = xor3(s[10], t[4], u);
+	s[15] = xor3(s[15], t[4], u);
+	s[20] = xor3(s[20], t[4], u);
+
+	u = ROL2(t[2], 1);
+	s[1] = xor3(s[1], t[0], u);
+	s[6] = xor3(s[6], t[0], u);
+	s[11] = xor3(s[11], t[0], u);
+	s[16] = xor3(s[16], t[0], u);
+	s[21] = xor3(s[21], t[0], u);
+
+	u = ROL2(t[3], 1);
+	s[2] = xor3(s[2], t[1], u);
+	s[7] = xor3(s[7], t[1], u);
+	s[12] = xor3(s[12], t[1], u);
+	s[17] = xor3(s[17], t[1], u);
+	s[22] = xor3(s[22], t[1], u);
+
+	u = ROL2(t[4], 1);
+	s[3] = xor3(s[3], t[2], u);
+	s[8] = xor3(s[8], t[2], u);
+	s[13] = xor3(s[13], t[2], u);
+	s[18] = xor3(s[18], t[2], u);
+	s[23] = xor3(s[23], t[2], u);
+
+	u = ROL2(t[0], 1);
+	s[4] = xor3(s[4], t[3], u);
+	s[9] = xor3(s[9], t[3], u);
+	s[14] = xor3(s[14], t[3], u);
+	s[19] = xor3(s[19], t[3], u);
+	s[24] = xor3(s[24], t[3], u);
+
+	/* rho pi: b[..] = rotl(a[..], ..) */
+	u = s[1];
+
+	s[1] = ROL2(s[6], 44);
+	s[6] = ROL2(s[9], 20);
+	s[9] = ROL2(s[22], 61);
+	s[22] = ROL2(s[14], 39);
+	s[14] = ROL2(s[20], 18);
+	s[20] = ROL2(s[2], 62);
+	s[2] = ROL2(s[12], 43);
+	s[12] = ROL2(s[13], 25);
+	s[13] = ROL2(s[19], 8);
+	s[19] = ROL2(s[23], 56);
+	s[23] = ROL2(s[15], 41);
+	s[15] = ROL2(s[4], 27);
+	s[4] = ROL2(s[24], 14);
+	s[24] = ROL2(s[21], 2);
+	s[21] = ROL2(s[8], 55);
+	s[8] = ROL2(s[16], 45);
+	s[16] = ROL2(s[5], 36);
+	s[5] = ROL2(s[3], 28);
+	s[3] = ROL2(s[18], 21);
+	s[18] = ROL2(s[17], 15);
+	s[17] = ROL2(s[11], 10);
+	s[11] = ROL2(s[7], 6);
+	s[7] = ROL2(s[10], 3);
+	s[10] = ROL2(u, 1);
+
+	/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
+
+	u = s[0]; v = s[1];
+	s[0] = chi(s[0], s[1], s[2]);
+	s[1] = chi(s[1], s[2], s[3]);
+	s[2] = chi(s[2], s[3], s[4]);
+	s[3] = chi(s[3], s[4], u);
+	s[4] = chi(s[4], u, v);
+
+	u = s[5]; v = s[6];
+	s[5] = chi(s[5], s[6], s[7]);
+	s[6] = chi(s[6], s[7], s[8]);
+	s[7] = chi(s[7], s[8], s[9]);
+	s[8] = chi(s[8], s[9], u);
+	s[9] = chi(s[9], u, v);
+
+	u = s[10]; v = s[11];
+	s[10] = chi(s[10], s[11], s[12]);
+	s[11] = chi(s[11], s[12], s[13]);
+	s[12] = chi(s[12], s[13], s[14]);
+	s[13] = chi(s[13], s[14], u);
+	s[14] = chi(s[14], u, v);
+
+	u = s[15]; v = s[16];
+	s[15] = chi(s[15], s[16], s[17]);
+	s[16] = chi(s[16], s[17], s[18]);
+	s[17] = chi(s[17], s[18], s[19]);
+	s[18] = chi(s[18], s[19], u);
+	s[19] = chi(s[19], u, v);
+
+	u = s[20]; v = s[21];
+	s[20] = chi(s[20], s[21], s[22]);
+	s[21] = chi(s[21], s[22], s[23]);
+	s[22] = chi(s[22], s[23], s[24]);
+	s[23] = chi(s[23], s[24], u);
+	s[24] = chi(s[24], u, v);
+
+	/* iota: a[0,0] ^= round constant */
+	s[0] ^= vectorize(keccak_round_constants[0]);
+
+	for (int i = 1; i < 23; i++)
+	{
+		/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
+		t[0] = xor5(s[0] , s[5] , s[10] , s[15] , s[20]);
+		t[1] = xor5(s[1] , s[6] , s[11] , s[16] , s[21]);
+		t[2] = xor5(s[2] , s[7] , s[12] , s[17] , s[22]);
+		t[3] = xor5(s[3] , s[8] , s[13] , s[18] , s[23]);
+		t[4] = xor5(s[4] , s[9] , s[14] , s[19] , s[24]);
+
+		/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
+		/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
+
+		u = ROL2(t[1], 1);
+		s[0]  = xor3(s[0], t[4], u);
+		s[5]  = xor3(s[5], t[4], u);
+		s[10] = xor3(s[10], t[4], u);
+		s[15] = xor3(s[15], t[4], u);
+		s[20] = xor3(s[20], t[4], u);
+
+		u = ROL2(t[2], 1);
+		s[1] = xor3(s[1], t[0], u);
+		s[6] = xor3(s[6], t[0], u);
+		s[11] = xor3(s[11], t[0], u);
+		s[16] = xor3(s[16], t[0], u);
+		s[21] = xor3(s[21], t[0], u);
+
+		u = ROL2(t[3], 1);
+		s[2] = xor3(s[2], t[1], u);
+		s[7] = xor3(s[7], t[1], u);
+		s[12] = xor3(s[12], t[1], u);
+		s[17] = xor3(s[17], t[1], u);
+		s[22] = xor3(s[22], t[1], u);
+
+		u = ROL2(t[4], 1);
+		s[3] = xor3(s[3], t[2], u);
+		s[8] = xor3(s[8], t[2], u);
+		s[13] = xor3(s[13], t[2], u);
+		s[18] = xor3(s[18], t[2], u);
+		s[23] = xor3(s[23], t[2], u);
+
+
+		u = ROL2(t[0], 1);
+		s[4] = xor3(s[4], t[3], u);
+		s[9] = xor3(s[9], t[3], u);
+		s[14] = xor3(s[14], t[3], u);
+		s[19] = xor3(s[19], t[3], u);
+		s[24] = xor3(s[24], t[3], u);
+
+		/* rho pi: b[..] = rotl(a[..], ..) */
+		u = s[1];
+
+		s[1] = ROL2(s[6], 44);
+		s[6] = ROL2(s[9], 20);
+		s[9] = ROL2(s[22], 61);
+		s[22] = ROL2(s[14], 39);
+		s[14] = ROL2(s[20], 18);
+		s[20] = ROL2(s[2], 62);
+		s[2] = ROL2(s[12], 43);
+		s[12] = ROL2(s[13], 25);
+		s[13] = ROL2(s[19], 8);
+		s[19] = ROL2(s[23], 56);
+		s[23] = ROL2(s[15], 41);
+		s[15] = ROL2(s[4], 27);
+		s[4] = ROL2(s[24], 14);
+		s[24] = ROL2(s[21], 2);
+		s[21] = ROL2(s[8], 55);
+		s[8] = ROL2(s[16], 45);
+		s[16] = ROL2(s[5], 36);
+		s[5] = ROL2(s[3], 28);
+		s[3] = ROL2(s[18], 21);
+		s[18] = ROL2(s[17], 15);
+		s[17] = ROL2(s[11], 10);
+		s[11] = ROL2(s[7], 6);
+		s[7] = ROL2(s[10], 3);
+		s[10] = ROL2(u, 1);
+
+		/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
+			
+		u = s[0]; v = s[1];
+		s[0] = chi(s[0], s[1], s[2]);
+		s[1] = chi(s[1], s[2], s[3]);
+		s[2] = chi(s[2], s[3], s[4]);
+		s[3] = chi(s[3], s[4], u);
+		s[4] = chi(s[4], u, v);
+
+		u = s[5]; v = s[6]; 
+		s[5] = chi(s[5], s[6], s[7]);
+		s[6] = chi(s[6], s[7], s[8]);
+		s[7] = chi(s[7], s[8], s[9]);
+		s[8] = chi(s[8], s[9], u);
+		s[9] = chi(s[9], u, v);
+
+		u = s[10]; v = s[11]; 
+		s[10] = chi(s[10], s[11], s[12]);
+		s[11] = chi(s[11], s[12], s[13]);
+		s[12] = chi(s[12], s[13], s[14]);
+		s[13] = chi(s[13], s[14], u);
+		s[14] = chi(s[14], u, v);
+
+		u = s[15]; v = s[16];
+		s[15] = chi(s[15], s[16], s[17]);
+		s[16] = chi(s[16], s[17], s[18]);
+		s[17] = chi(s[17], s[18], s[19]);
+		s[18] = chi(s[18], s[19], u);
+		s[19] = chi(s[19], u, v);
+
+		u = s[20]; v = s[21];
+		s[20] = chi(s[20], s[21], s[22]);
+		s[21] = chi(s[21], s[22], s[23]);
+		s[22] = chi(s[22], s[23], s[24]);
+		s[23] = chi(s[23], s[24], u);
+		s[24] = chi(s[24], u, v);
+
+		/* iota: a[0,0] ^= round constant */
+		s[0] ^= vectorize(keccak_round_constants[i]);
+	}
+
+	/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
+	t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
+	t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
+	t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
+	t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
+	t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
+
+	/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
+	/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
+
+	u = ROL2(t[1], 1);
+	s[0] = xor3(s[0], t[4], u);
+	s[10] = xor3(s[10], t[4], u);
+
+	u = ROL2(t[2], 1);
+	s[6] = xor3(s[6], t[0], u);
+	s[16] = xor3(s[16], t[0], u);
+
+	u = ROL2(t[3], 1);
+	s[12] = xor3(s[12], t[1], u);
+	s[22] = xor3(s[22], t[1], u);
+
+	u = ROL2(t[4], 1);
+	s[3] = xor3(s[3], t[2], u);
+	s[18] = xor3(s[18], t[2], u);
+
+	u = ROL2(t[0], 1);
+	s[9] = xor3(s[9], t[3], u);
+	s[24] = xor3(s[24], t[3], u);
+
+	/* rho pi: b[..] = rotl(a[..], ..) */
+	u = s[1];
+
+	s[1] = ROL2(s[6], 44);
+	s[6] = ROL2(s[9], 20);
+	s[9] = ROL2(s[22], 61);
+	s[2] = ROL2(s[12], 43);
+	s[4] = ROL2(s[24], 14);
+	s[8] = ROL2(s[16], 45);
+	s[5] = ROL2(s[3], 28);
+	s[3] = ROL2(s[18], 21);
+	s[7] = ROL2(s[10], 3);
+
+	/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
+
+	u = s[0]; v = s[1];
+	s[0] = chi(s[0], s[1], s[2]);
+	s[1] = chi(s[1], s[2], s[3]);
+	s[2] = chi(s[2], s[3], s[4]);
+	s[3] = chi(s[3], s[4], u);
+	s[4] = chi(s[4], u, v);
+	s[5] = chi(s[5], s[6], s[7]);
+	s[6] = chi(s[6], s[7], s[8]);
+	s[7] = chi(s[7], s[8], s[9]);
+
+	/* iota: a[0,0] ^= round constant */
+	s[0] ^= vectorize(keccak_round_constants[23]);
+
+	for(int i = 0; i < 12; ++i)
+	    state[i] = s[i];
+}
+
+__device__ __forceinline__ uint64_t keccak_f1600_final(uint2* state)
+{
+	uint2 s[25];
+	uint2 t[5], u, v;
+
+	for (int i = 0; i < 12; ++i)
+		s[i] = state[i];
+
+	for (uint32_t i = 12; i < 25; i++)
+	{
+		s[i] = make_uint2(0, 0);
+	}
+	s[12].x = 1;
+	s[16].y = 0x80000000;
+	
+	/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
+	t[0] = xor3(s[0], s[5], s[10]);
+	t[1] = xor3(s[1], s[6], s[11]) ^ s[16];
+	t[2] = xor3(s[2], s[7], s[12]);
+	t[3] = s[3] ^ s[8];
+	t[4] = s[4] ^ s[9];
+
+	/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
+	/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
+
+	u = ROL2(t[1], 1);
+	s[0] = xor3(s[0], t[4], u);
+	s[5] = xor3(s[5], t[4], u);
+	s[10] = xor3(s[10], t[4], u);
+	s[15] = xor3(s[15], t[4], u);
+	s[20] = xor3(s[20], t[4], u);
+
+	u = ROL2(t[2], 1);
+	s[1] = xor3(s[1], t[0], u);
+	s[6] = xor3(s[6], t[0], u);
+	s[11] = xor3(s[11], t[0], u);
+	s[16] = xor3(s[16], t[0], u);
+	s[21] = xor3(s[21], t[0], u);
+
+	u = ROL2(t[3], 1);
+	s[2] = xor3(s[2], t[1], u);
+	s[7] = xor3(s[7], t[1], u);
+	s[12] = xor3(s[12], t[1], u);
+	s[17] = xor3(s[17], t[1], u);
+	s[22] = xor3(s[22], t[1], u);
+
+	u = ROL2(t[4], 1);
+	s[3] = xor3(s[3], t[2], u);
+	s[8] = xor3(s[8], t[2], u);
+	s[13] = xor3(s[13], t[2], u);
+	s[18] = xor3(s[18], t[2], u);
+	s[23] = xor3(s[23], t[2], u);
+
+
+	u = ROL2(t[0], 1);
+	s[4] = xor3(s[4], t[3], u);
+	s[9] = xor3(s[9], t[3], u);
+	s[14] = xor3(s[14], t[3], u);
+	s[19] = xor3(s[19], t[3], u);
+	s[24] = xor3(s[24], t[3], u);
+
+	/* rho pi: b[..] = rotl(a[..], ..) */
+	u = s[1];
+
+	s[1] = ROL2(s[6], 44);
+	s[6] = ROL2(s[9], 20);
+	s[9] = ROL2(s[22], 61);
+	s[22] = ROL2(s[14], 39);
+	s[14] = ROL2(s[20], 18);
+	s[20] = ROL2(s[2], 62);
+	s[2] = ROL2(s[12], 43);
+	s[12] = ROL2(s[13], 25);
+	s[13] = ROL2(s[19], 8);
+	s[19] = ROL2(s[23], 56);
+	s[23] = ROL2(s[15], 41);
+	s[15] = ROL2(s[4], 27);
+	s[4] = ROL2(s[24], 14);
+	s[24] = ROL2(s[21], 2);
+	s[21] = ROL2(s[8], 55);
+	s[8] = ROL2(s[16], 45);
+	s[16] = ROL2(s[5], 36);
+	s[5] = ROL2(s[3], 28);
+	s[3] = ROL2(s[18], 21);
+	s[18] = ROL2(s[17], 15);
+	s[17] = ROL2(s[11], 10);
+	s[11] = ROL2(s[7], 6);
+	s[7] = ROL2(s[10], 3);
+	s[10] = ROL2(u, 1);
+
+	/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
+	u = s[0]; v = s[1];
+	s[0] = chi(s[0], s[1], s[2]);
+	s[1] = chi(s[1], s[2], s[3]);
+	s[2] = chi(s[2], s[3], s[4]);
+	s[3] = chi(s[3], s[4], u);
+	s[4] = chi(s[4], u, v);
+
+	u = s[5]; v = s[6];
+	s[5] = chi(s[5], s[6], s[7]);
+	s[6] = chi(s[6], s[7], s[8]);
+	s[7] = chi(s[7], s[8], s[9]);
+	s[8] = chi(s[8], s[9], u);
+	s[9] = chi(s[9], u, v);
+
+	u = s[10]; v = s[11];
+	s[10] = chi(s[10], s[11], s[12]);
+	s[11] = chi(s[11], s[12], s[13]);
+	s[12] = chi(s[12], s[13], s[14]);
+	s[13] = chi(s[13], s[14], u);
+	s[14] = chi(s[14], u, v);
+
+	u = s[15]; v = s[16];
+	s[15] = chi(s[15], s[16], s[17]);
+	s[16] = chi(s[16], s[17], s[18]);
+	s[17] = chi(s[17], s[18], s[19]);
+	s[18] = chi(s[18], s[19], u);
+	s[19] = chi(s[19], u, v);
+
+	u = s[20]; v = s[21];
+	s[20] = chi(s[20], s[21], s[22]);
+	s[21] = chi(s[21], s[22], s[23]);
+	s[22] = chi(s[22], s[23], s[24]);
+	s[23] = chi(s[23], s[24], u);
+	s[24] = chi(s[24], u, v);
+
+	/* iota: a[0,0] ^= round constant */
+	s[0] ^= vectorize(keccak_round_constants[0]);
+
+	for (int i = 1; i < 23; i++)
+	{
+		/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
+		t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
+		t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
+		t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
+		t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
+		t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
+
+		/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
+		/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
+
+		u = ROL2(t[1], 1);
+		s[0] = xor3(s[0], t[4], u);
+		s[5] = xor3(s[5], t[4], u);
+		s[10] = xor3(s[10], t[4], u);
+		s[15] = xor3(s[15], t[4], u);
+		s[20] = xor3(s[20], t[4], u);
+
+		u = ROL2(t[2], 1);
+		s[1] = xor3(s[1], t[0], u);
+		s[6] = xor3(s[6], t[0], u);
+		s[11] = xor3(s[11], t[0], u);
+		s[16] = xor3(s[16], t[0], u);
+		s[21] = xor3(s[21], t[0], u);
+
+		u = ROL2(t[3], 1);
+		s[2] = xor3(s[2], t[1], u);
+		s[7] = xor3(s[7], t[1], u);
+		s[12] = xor3(s[12], t[1], u);
+		s[17] = xor3(s[17], t[1], u);
+		s[22] = xor3(s[22], t[1], u);
+
+		u = ROL2(t[4], 1);
+		s[3] = xor3(s[3], t[2], u);
+		s[8] = xor3(s[8], t[2], u);
+		s[13] = xor3(s[13], t[2], u);
+		s[18] = xor3(s[18], t[2], u);
+		s[23] = xor3(s[23], t[2], u);
+
+
+		u = ROL2(t[0], 1);
+		s[4] = xor3(s[4], t[3], u);
+		s[9] = xor3(s[9], t[3], u);
+		s[14] = xor3(s[14], t[3], u);
+		s[19] = xor3(s[19], t[3], u);
+		s[24] = xor3(s[24], t[3], u);
+
+		/* rho pi: b[..] = rotl(a[..], ..) */
+		u = s[1];
+
+		s[1] = ROL2(s[6], 44);
+		s[6] = ROL2(s[9], 20);
+		s[9] = ROL2(s[22], 61);
+		s[22] = ROL2(s[14], 39);
+		s[14] = ROL2(s[20], 18);
+		s[20] = ROL2(s[2], 62);
+		s[2] = ROL2(s[12], 43);
+		s[12] = ROL2(s[13], 25);
+		s[13] = ROL2(s[19], 8);
+		s[19] = ROL2(s[23], 56);
+		s[23] = ROL2(s[15], 41);
+		s[15] = ROL2(s[4], 27);
+		s[4] = ROL2(s[24], 14);
+		s[24] = ROL2(s[21], 2);
+		s[21] = ROL2(s[8], 55);
+		s[8] = ROL2(s[16], 45);
+		s[16] = ROL2(s[5], 36);
+		s[5] = ROL2(s[3], 28);
+		s[3] = ROL2(s[18], 21);
+		s[18] = ROL2(s[17], 15);
+		s[17] = ROL2(s[11], 10);
+		s[11] = ROL2(s[7], 6);
+		s[7] = ROL2(s[10], 3);
+		s[10] = ROL2(u, 1);
+
+		/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
+		u = s[0]; v = s[1];
+		s[0] = chi(s[0], s[1], s[2]);	
+		s[1] = chi(s[1], s[2], s[3]);
+		s[2] = chi(s[2], s[3], s[4]);
+		s[3] = chi(s[3], s[4], u);
+		s[4] = chi(s[4], u, v);
+
+		u = s[5]; v = s[6];
+		s[5] = chi(s[5], s[6], s[7]);
+		s[6] = chi(s[6], s[7], s[8]);
+		s[7] = chi(s[7], s[8], s[9]);
+		s[8] = chi(s[8], s[9], u);
+		s[9] = chi(s[9], u, v);
+
+		u = s[10]; v = s[11];
+		s[10] = chi(s[10], s[11], s[12]);
+		s[11] = chi(s[11], s[12], s[13]);
+		s[12] = chi(s[12], s[13], s[14]);
+		s[13] = chi(s[13], s[14], u);
+		s[14] = chi(s[14], u, v);
+
+		u = s[15]; v = s[16];
+		s[15] = chi(s[15], s[16], s[17]);
+		s[16] = chi(s[16], s[17], s[18]);
+		s[17] = chi(s[17], s[18], s[19]);
+		s[18] = chi(s[18], s[19], u);
+		s[19] = chi(s[19], u, v);
+
+		u = s[20]; v = s[21];
+		s[20] = chi(s[20], s[21], s[22]);
+		s[21] = chi(s[21], s[22], s[23]);
+		s[22] = chi(s[22], s[23], s[24]);
+		s[23] = chi(s[23], s[24], u);
+		s[24] = chi(s[24], u, v);
+
+		/* iota: a[0,0] ^= round constant */
+		s[0] ^= vectorize(keccak_round_constants[i]);
+	}
+
+	t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
+	t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
+	t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
+	t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
+	t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
+
+	s[0] = xor3(s[0], t[4], ROL2(t[1], 1));
+	s[6] = xor3(s[6], t[0], ROL2(t[2], 1));
+	s[12] = xor3(s[12], t[1], ROL2(t[3], 1));
+
+	s[1] = ROL2(s[6], 44);
+	s[2] = ROL2(s[12], 43);
+
+	s[0] = chi(s[0], s[1], s[2]);
+
+	/* iota: a[0,0] ^= round constant */
+	//s[0] ^= vectorize(keccak_round_constants[23]);
+	return devectorize(s[0]) ^ keccak_round_constants[23];
+}
+
+__device__ __forceinline__ void SHA3_512(uint2* s) {
+	
+	uint2 t[5], u, v;
+
+	for (uint32_t i = 8; i < 25; i++)
+	{
+		s[i] = make_uint2(0, 0);
+	}
+	s[8].x = 1;
+	s[8].y = 0x80000000;
+
+	for (int i = 0; i < 23; i++)
+	{
+		/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
+		t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
+		t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
+		t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
+		t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
+		t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
+
+		/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
+		/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
+
+		u = ROL2(t[1], 1);
+		s[0] = xor3(s[0], t[4], u);
+		s[5] = xor3(s[5], t[4], u);
+		s[10] = xor3(s[10], t[4], u);
+		s[15] = xor3(s[15], t[4], u);
+		s[20] = xor3(s[20], t[4], u);
+
+		u = ROL2(t[2], 1);
+		s[1] = xor3(s[1], t[0], u);
+		s[6] = xor3(s[6], t[0], u);
+		s[11] = xor3(s[11], t[0], u);
+		s[16] = xor3(s[16], t[0], u);
+		s[21] = xor3(s[21], t[0], u);
+
+		u = ROL2(t[3], 1);
+		s[2] = xor3(s[2], t[1], u);
+		s[7] = xor3(s[7], t[1], u);
+		s[12] = xor3(s[12], t[1], u);
+		s[17] = xor3(s[17], t[1], u);
+		s[22] = xor3(s[22], t[1], u);
+
+		u = ROL2(t[4], 1);
+		s[3] = xor3(s[3], t[2], u);
+		s[8] = xor3(s[8], t[2], u);
+		s[13] = xor3(s[13], t[2], u);
+		s[18] = xor3(s[18], t[2], u);
+		s[23] = xor3(s[23], t[2], u);
+
+
+		u = ROL2(t[0], 1);
+		s[4] = xor3(s[4], t[3], u);
+		s[9] = xor3(s[9], t[3], u);
+		s[14] = xor3(s[14], t[3], u);
+		s[19] = xor3(s[19], t[3], u);
+		s[24] = xor3(s[24], t[3], u);
+
+		/* rho pi: b[..] = rotl(a[..], ..) */
+		u = s[1];
+
+		s[1] = ROL2(s[6], 44);
+		s[6] = ROL2(s[9], 20);
+		s[9] = ROL2(s[22], 61);
+		s[22] = ROL2(s[14], 39);
+		s[14] = ROL2(s[20], 18);
+		s[20] = ROL2(s[2], 62);
+		s[2] = ROL2(s[12], 43);
+		s[12] = ROL2(s[13], 25);
+		s[13] = ROL2(s[19], 8);
+		s[19] = ROL2(s[23], 56);
+		s[23] = ROL2(s[15], 41);
+		s[15] = ROL2(s[4], 27);
+		s[4] = ROL2(s[24], 14);
+		s[24] = ROL2(s[21], 2);
+		s[21] = ROL2(s[8], 55);
+		s[8] = ROL2(s[16], 45);
+		s[16] = ROL2(s[5], 36);
+		s[5] = ROL2(s[3], 28);
+		s[3] = ROL2(s[18], 21);
+		s[18] = ROL2(s[17], 15);
+		s[17] = ROL2(s[11], 10);
+		s[11] = ROL2(s[7], 6);
+		s[7] = ROL2(s[10], 3);
+		s[10] = ROL2(u, 1);
+
+		/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
+		u = s[0]; v = s[1];
+		s[0] = chi(s[0], s[1], s[2]);
+		s[1] = chi(s[1], s[2], s[3]);
+		s[2] = chi(s[2], s[3], s[4]);
+		s[3] = chi(s[3], s[4], u);
+		s[4] = chi(s[4], u, v);
+
+		u = s[5]; v = s[6];
+		s[5] = chi(s[5], s[6], s[7]);
+		s[6] = chi(s[6], s[7], s[8]);
+		s[7] = chi(s[7], s[8], s[9]);
+		s[8] = chi(s[8], s[9], u);
+		s[9] = chi(s[9], u, v);
+
+		u = s[10]; v = s[11];
+		s[10] = chi(s[10], s[11], s[12]);
+		s[11] = chi(s[11], s[12], s[13]);
+		s[12] = chi(s[12], s[13], s[14]);
+		s[13] = chi(s[13], s[14], u);
+		s[14] = chi(s[14], u, v);
+
+		u = s[15]; v = s[16];
+		s[15] = chi(s[15], s[16], s[17]);
+		s[16] = chi(s[16], s[17], s[18]);
+		s[17] = chi(s[17], s[18], s[19]);
+		s[18] = chi(s[18], s[19], u);
+		s[19] = chi(s[19], u, v);
+
+		u = s[20]; v = s[21];
+		s[20] = chi(s[20], s[21], s[22]);
+		s[21] = chi(s[21], s[22], s[23]);
+		s[22] = chi(s[22], s[23], s[24]);
+		s[23] = chi(s[23], s[24], u);
+		s[24] = chi(s[24], u, v);
+
+		/* iota: a[0,0] ^= round constant */
+		s[0] ^= vectorize(keccak_round_constants[i]);
+	}
+
+	/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
+	t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
+	t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
+	t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
+	t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
+	t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
+
+	/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
+	/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
+
+	u = ROL2(t[1], 1);
+	s[0] = xor3(s[0], t[4], u);
+	s[10] = xor3(s[10], t[4], u);
+
+	u = ROL2(t[2], 1);
+	s[6] = xor3(s[6], t[0], u);
+	s[16] = xor3(s[16], t[0], u);
+
+	u = ROL2(t[3], 1);
+	s[12] = xor3(s[12], t[1], u);
+	s[22] = xor3(s[22], t[1], u);
+
+	u = ROL2(t[4], 1);
+	s[3] = xor3(s[3], t[2], u);
+	s[18] = xor3(s[18], t[2], u);
+
+	u = ROL2(t[0], 1);
+	s[9] = xor3(s[9], t[3], u);
+	s[24] = xor3(s[24], t[3], u);
+
+	/* rho pi: b[..] = rotl(a[..], ..) */
+	u = s[1];
+
+	s[1] = ROL2(s[6], 44);
+	s[6] = ROL2(s[9], 20);
+	s[9] = ROL2(s[22], 61);
+	s[2] = ROL2(s[12], 43);
+	s[4] = ROL2(s[24], 14);
+	s[8] = ROL2(s[16], 45);
+	s[5] = ROL2(s[3], 28);
+	s[3] = ROL2(s[18], 21);
+	s[7] = ROL2(s[10], 3);
+
+	/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
+
+	u = s[0]; v = s[1];
+	s[0] = chi(s[0], s[1], s[2]);
+	s[1] = chi(s[1], s[2], s[3]);
+	s[2] = chi(s[2], s[3], s[4]);
+	s[3] = chi(s[3], s[4], u);
+	s[4] = chi(s[4], u, v);
+	s[5] = chi(s[5], s[6], s[7]);
+	s[6] = chi(s[6], s[7], s[8]);
+	s[7] = chi(s[7], s[8], s[9]);
+
+	/* iota: a[0,0] ^= round constant */
+	s[0] ^= vectorize(keccak_round_constants[23]);
+}

From cb8c497d58014304888ff0394fcd3d16a774c7b2 Mon Sep 17 00:00:00 2001
From: davilizh <davili@nvidia.com>
Date: Tue, 20 Jun 2017 18:36:31 +0800
Subject: [PATCH 2/2] The code is optimized for GTX1060, can improve GTX1060
 with 2 GPC performance by 15%, and GTX1060 with 1 GPC performance by more
 than 30%. Meanwhile, it also increases performance on GTX1070 by 3%, on
 Telsla M60 by 2%, and should also benefit other chips. However, also find 5%
 decrease for Nvidia GRID K520.

---
 dagger_shuffled.cuh                        |  94 ----
 ethash_cuda_miner_kernel.cu                | 155 ------
 keccak.cuh                                 | 787 -----------------------------
 libethash-cuda/dagger_shuffled.cuh         | 104 ++--
 libethash-cuda/ethash_cuda_miner_kernel.cu |   6 -
 libethash-cuda/keccak.cuh                  |  16 +-
 6 files changed, 69 insertions(+), 1093 deletions(-)
 delete mode 100644 dagger_shuffled.cuh
 delete mode 100644 ethash_cuda_miner_kernel.cu
 delete mode 100644 keccak.cuh

diff --git a/dagger_shuffled.cuh b/dagger_shuffled.cuh
deleted file mode 100644
index 9d5754585a..0000000000
--- a/dagger_shuffled.cuh
+++ /dev/null
@@ -1,94 +0,0 @@
-#include "ethash_cuda_miner_kernel_globals.h"
-#include "ethash_cuda_miner_kernel.h"
-#include "cuda_helper.h"
-
-#define PARALLEL_HASH 4
-
-__device__ uint64_t compute_hash(
-	uint64_t nonce
-	)
-{
-	// sha3_512(header .. nonce)
-	uint2 state[12];
-	
-	state[4] = vectorize(nonce);
-
-	keccak_f1600_init(state);
-	
-	// Threads work together in this phase in groups of 8.
-	const int thread_id  = threadIdx.x &  (THREADS_PER_HASH - 1);
-	const int mix_idx    = thread_id & 3;
-
-	for (int i = 0; i < THREADS_PER_HASH; i += PARALLEL_HASH)
-	{
-		uint4 mix[PARALLEL_HASH];
-		uint32_t offset[PARALLEL_HASH];
-		uint32_t init0[PARALLEL_HASH];
-	
-		// share init among threads
-		for (int p = 0; p < PARALLEL_HASH; p++)
-		{
-			uint2 shuffle[8];
-			for (int j = 0; j < 8; j++) 
-			{
-				shuffle[j].x = __shfl(state[j].x, i+p, THREADS_PER_HASH);
-				shuffle[j].y = __shfl(state[j].y, i+p, THREADS_PER_HASH);
-			}
-			switch (mix_idx)
-			{
-				case 0: mix[p] = vectorize2(shuffle[0], shuffle[1]); break;
-				case 1: mix[p] = vectorize2(shuffle[2], shuffle[3]); break;
-				case 2: mix[p] = vectorize2(shuffle[4], shuffle[5]); break;
-				case 3: mix[p] = vectorize2(shuffle[6], shuffle[7]); break;
-			}
-			init0[p] = __shfl(shuffle[0].x, 0, THREADS_PER_HASH);
-		}
-
-		for (uint32_t a = 0; a < ACCESSES; a += 4)
-		{
-			int t = bfe(a, 2u, 3u);
-
-			for (uint32_t b = 0; b < 4; b++)
-			{
-				for (int p = 0; p < PARALLEL_HASH; p++)
-				{
-					offset[p] = fnv(init0[p] ^ (a + b), ((uint32_t *)&mix[p])[b]) % d_dag_size;
-					offset[p] = __shfl(offset[p], t, THREADS_PER_HASH);
-				}
-				#pragma unroll
-				for (int p = 0; p < PARALLEL_HASH; p++)
-				{
-					mix[p] = fnv4(mix[p], d_dag[offset[p]].uint4s[thread_id]);
-				}
-			}
-		}
-
-		for (int p = 0; p < PARALLEL_HASH; p++)
-		{
-			uint2 shuffle[4];
-			uint32_t thread_mix = fnv_reduce(mix[p]);
-
-			// update mix accross threads
-
-			shuffle[0].x = __shfl(thread_mix, 0, THREADS_PER_HASH);
-			shuffle[0].y = __shfl(thread_mix, 1, THREADS_PER_HASH);
-			shuffle[1].x = __shfl(thread_mix, 2, THREADS_PER_HASH);
-			shuffle[1].y = __shfl(thread_mix, 3, THREADS_PER_HASH);
-			shuffle[2].x = __shfl(thread_mix, 4, THREADS_PER_HASH);
-			shuffle[2].y = __shfl(thread_mix, 5, THREADS_PER_HASH);
-			shuffle[3].x = __shfl(thread_mix, 6, THREADS_PER_HASH);
-			shuffle[3].y = __shfl(thread_mix, 7, THREADS_PER_HASH);
-
-			if ((i+p) == thread_id) {
-				//move mix into state:
-				state[8] = shuffle[0];
-				state[9] = shuffle[1];
-				state[10] = shuffle[2];
-				state[11] = shuffle[3];
-			}
-		}
-	}
-	
-	// keccak_256(keccak_512(header..nonce) .. mix);
-	return keccak_f1600_final(state);
-}
diff --git a/ethash_cuda_miner_kernel.cu b/ethash_cuda_miner_kernel.cu
deleted file mode 100644
index ac607c3a20..0000000000
--- a/ethash_cuda_miner_kernel.cu
+++ /dev/null
@@ -1,155 +0,0 @@
-/*
-* Genoil's CUDA mining kernel for Ethereum
-* based on Tim Hughes' opencl kernel.
-* thanks to sp_, trpuvot, djm34, cbuchner for things i took from ccminer.
-*/
-
-#include "ethash_cuda_miner_kernel.h"
-#include "ethash_cuda_miner_kernel_globals.h"
-#include "cuda_helper.h"
-
-#include "fnv.cuh"
-
-#define copy(dst, src, count) for (int i = 0; i != count; ++i) { (dst)[i] = (src)[i]; }
-
-
-#if __CUDA_ARCH__ < SHUFFLE_MIN_VER
-#include "keccak_u64.cuh"
-#include "dagger_shared.cuh"
-#else
-#include "keccak.cuh"
-#include "dagger_shuffled.cuh"
-#endif
-
-__global__ void 
-ethash_search(
-	volatile uint32_t* g_output,
-	uint64_t start_nonce
-	)
-{
-	uint32_t const gid = blockIdx.x * blockDim.x + threadIdx.x;	
-	uint64_t hash = compute_hash(start_nonce + gid);
-	if (cuda_swab64(hash) > d_target) return;
-	uint32_t index = atomicInc(const_cast<uint32_t*>(g_output), SEARCH_RESULT_BUFFER_SIZE - 1) + 1;
-	g_output[index] = gid;
-}
-
-void run_ethash_search(
-	uint32_t blocks,
-	uint32_t threads,
-	uint32_t sharedbytes,
-	cudaStream_t stream,
-	volatile uint32_t* g_output,
-	uint64_t start_nonce
-)
-{
-	ethash_search << <blocks, threads, sharedbytes, stream >> >(g_output, start_nonce);
-	CUDA_SAFE_CALL(cudaGetLastError());
-}
-
-#define ETHASH_DATASET_PARENTS 256
-#define NODE_WORDS (64/4)
-
-__global__ void
-ethash_calculate_dag_item(uint32_t start)
-{
-	uint32_t const node_index = start + blockIdx.x * blockDim.x + threadIdx.x;
-	if (node_index > d_dag_size * 2) return;
-
-	hash200_t dag_node;
-	copy(dag_node.uint4s, d_light[node_index % d_light_size].uint4s, 4);
-	dag_node.words[0] ^= node_index;
-	SHA3_512(dag_node.uint2s);
-
-	const int thread_id = threadIdx.x & 3;
-
-	for (uint32_t i = 0; i != ETHASH_DATASET_PARENTS; ++i) {
-		uint32_t parent_index = fnv(node_index ^ i, dag_node.words[i % NODE_WORDS]) % d_light_size;
-#if __CUDA_ARCH__ < SHUFFLE_MIN_VER
-		for (unsigned w = 0; w != 4; ++w) {
-			dag_node.uint4s[w] = fnv4(dag_node.uint4s[w], d_light[parent_index].uint4s[w]);
-		}
-#else
-		for (uint32_t t = 0; t < 4; t++) {
-			uint32_t shuffle_index = __shfl(parent_index, t, 4);
-			uint4 p4 = d_light[shuffle_index].uint4s[thread_id];
-
-			for (int w = 0; w < 4; w++) {
-				uint4 s4 = make_uint4(__shfl(p4.x, w, 4), __shfl(p4.y, w, 4), __shfl(p4.z, w, 4), __shfl(p4.w, w, 4));
-				if (t == thread_id) {
-					dag_node.uint4s[w] = fnv4(dag_node.uint4s[w], s4);
-				}
-			}
-
-		}
-#endif		
-	}
-	SHA3_512(dag_node.uint2s);
-	hash64_t * dag_nodes = (hash64_t *)d_dag;
-
-#if __CUDA_ARCH__ < SHUFFLE_MIN_VER
-	for (uint32_t i = 0; i < 4; i++) {
-		dag_nodes[node_index].uint4s[i] =  dag_node.uint4s[i];
-	}
-#else
-	for (uint32_t t = 0; t < 4; t++) {
-
-		uint32_t shuffle_index = __shfl(node_index, t, 4);
-		uint4 s[4];
-		for (uint32_t w = 0; w < 4; w++) {
-			s[w] = make_uint4(__shfl(dag_node.uint4s[w].x, t, 4), __shfl(dag_node.uint4s[w].y, t, 4), __shfl(dag_node.uint4s[w].z, t, 4), __shfl(dag_node.uint4s[w].w, t, 4));
-		}
-		dag_nodes[shuffle_index].uint4s[thread_id] = s[thread_id];
-	}
-#endif		 
-}
-
-void ethash_generate_dag(
-	uint64_t dag_size,
-	uint32_t blocks,
-	uint32_t threads,
-	cudaStream_t stream,
-	int device
-	)
-{
-	uint32_t const work = (uint32_t)(dag_size / sizeof(hash64_t));
-
-	uint32_t fullRuns = work / (blocks * threads);
-	uint32_t const restWork = work % (blocks * threads);
-	if (restWork > 0) fullRuns++;
-	for (uint32_t i = 0; i < fullRuns; i++)
-	{
-		ethash_calculate_dag_item <<<blocks, threads, 0, stream >>>(i * blocks * threads);
-		CUDA_SAFE_CALL(cudaDeviceSynchronize());
-		printf("CUDA#%d: %.0f%%\n",device, 100.0f * (float)i / (float)fullRuns);
-	}
-	//printf("GPU#%d 100%%\n");
-	CUDA_SAFE_CALL(cudaGetLastError());
-}
-
-void set_constants(
-	hash128_t* _dag,
-	uint32_t _dag_size,
-	hash64_t * _light,
-	uint32_t _light_size
-	)
-{
-	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_dag, &_dag, sizeof(hash128_t *)));
-	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_dag_size, &_dag_size, sizeof(uint32_t)));
-	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_light, &_light, sizeof(hash64_t *)));
-	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_light_size, &_light_size, sizeof(uint32_t)));
-}
-
-void set_header(
-	hash32_t _header
-	)
-{
-	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_header, &_header, sizeof(hash32_t)));
-}
-
-void set_target(
-	uint64_t _target
-	)
-{
-	CUDA_SAFE_CALL(cudaMemcpyToSymbol(d_target, &_target, sizeof(uint64_t)));
-}
diff --git a/keccak.cuh b/keccak.cuh
deleted file mode 100644
index ede8ecf54e..0000000000
--- a/keccak.cuh
+++ /dev/null
@@ -1,787 +0,0 @@
-#include "cuda_helper.h"
-
-__device__ __constant__ uint64_t const keccak_round_constants[24] = {
-	0x0000000000000001ULL, 0x0000000000008082ULL, 0x800000000000808AULL,
-	0x8000000080008000ULL, 0x000000000000808BULL, 0x0000000080000001ULL,
-	0x8000000080008081ULL, 0x8000000000008009ULL, 0x000000000000008AULL,
-	0x0000000000000088ULL, 0x0000000080008009ULL, 0x000000008000000AULL,
-	0x000000008000808BULL, 0x800000000000008BULL, 0x8000000000008089ULL,
-	0x8000000000008003ULL, 0x8000000000008002ULL, 0x8000000000000080ULL,
-	0x000000000000800AULL, 0x800000008000000AULL, 0x8000000080008081ULL,
-	0x8000000000008080ULL, 0x0000000080000001ULL, 0x8000000080008008ULL
-};
-
-__device__ __forceinline__
-uint2 xor5(const uint2 a, const uint2 b, const uint2 c, const uint2 d, const uint2 e) {
-	return a ^ b ^ c ^ d ^ e;
-}
-__device__ __forceinline__
-uint2 xor3(const uint2 a, const uint2 b, const uint2 c) {
-	return a ^ b ^ c;
-}
-
-__device__ __forceinline__
-uint2 chi(const uint2 a, const uint2 b, const uint2 c) {
-	return a ^ (~b) & c;
-}
-
-__device__ __forceinline__ void keccak_f1600_init(uint2* state)
-{
-	uint2 s[25];
-	uint2 t[5], u, v;
-
-	s[4] = state[4];
-
-	devectorize2(d_header.uint4s[0], s[0], s[1]);
-	devectorize2(d_header.uint4s[1], s[2], s[3]);
-
-	for (uint32_t i = 5; i < 25; i++)
-	{
-		s[i] = make_uint2(0, 0);
-	}
-	s[5].x = 1;
-	s[8].y = 0x80000000;
-
-	/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
-	t[0].x = s[0].x ^ s[5].x;
-	t[0].y = s[0].y;
-	t[1] = s[1];
-	t[2] = s[2];
-	t[3].x = s[3].x;
-	t[3].y = s[3].y ^ s[8].y;
-	t[4] = s[4];
-
-	/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
-	/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
-
-	u = ROL2(t[1], 1);
-	s[0] = xor3(s[0], t[4], u);
-	s[5] = xor3(s[5], t[4], u);
-	s[10] = xor3(s[10], t[4], u);
-	s[15] = xor3(s[15], t[4], u);
-	s[20] = xor3(s[20], t[4], u);
-
-	u = ROL2(t[2], 1);
-	s[1] = xor3(s[1], t[0], u);
-	s[6] = xor3(s[6], t[0], u);
-	s[11] = xor3(s[11], t[0], u);
-	s[16] = xor3(s[16], t[0], u);
-	s[21] = xor3(s[21], t[0], u);
-
-	u = ROL2(t[3], 1);
-	s[2] = xor3(s[2], t[1], u);
-	s[7] = xor3(s[7], t[1], u);
-	s[12] = xor3(s[12], t[1], u);
-	s[17] = xor3(s[17], t[1], u);
-	s[22] = xor3(s[22], t[1], u);
-
-	u = ROL2(t[4], 1);
-	s[3] = xor3(s[3], t[2], u);
-	s[8] = xor3(s[8], t[2], u);
-	s[13] = xor3(s[13], t[2], u);
-	s[18] = xor3(s[18], t[2], u);
-	s[23] = xor3(s[23], t[2], u);
-
-	u = ROL2(t[0], 1);
-	s[4] = xor3(s[4], t[3], u);
-	s[9] = xor3(s[9], t[3], u);
-	s[14] = xor3(s[14], t[3], u);
-	s[19] = xor3(s[19], t[3], u);
-	s[24] = xor3(s[24], t[3], u);
-
-	/* rho pi: b[..] = rotl(a[..], ..) */
-	u = s[1];
-
-	s[1] = ROL2(s[6], 44);
-	s[6] = ROL2(s[9], 20);
-	s[9] = ROL2(s[22], 61);
-	s[22] = ROL2(s[14], 39);
-	s[14] = ROL2(s[20], 18);
-	s[20] = ROL2(s[2], 62);
-	s[2] = ROL2(s[12], 43);
-	s[12] = ROL2(s[13], 25);
-	s[13] = ROL2(s[19], 8);
-	s[19] = ROL2(s[23], 56);
-	s[23] = ROL2(s[15], 41);
-	s[15] = ROL2(s[4], 27);
-	s[4] = ROL2(s[24], 14);
-	s[24] = ROL2(s[21], 2);
-	s[21] = ROL2(s[8], 55);
-	s[8] = ROL2(s[16], 45);
-	s[16] = ROL2(s[5], 36);
-	s[5] = ROL2(s[3], 28);
-	s[3] = ROL2(s[18], 21);
-	s[18] = ROL2(s[17], 15);
-	s[17] = ROL2(s[11], 10);
-	s[11] = ROL2(s[7], 6);
-	s[7] = ROL2(s[10], 3);
-	s[10] = ROL2(u, 1);
-
-	/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
-
-	u = s[0]; v = s[1];
-	s[0] = chi(s[0], s[1], s[2]);
-	s[1] = chi(s[1], s[2], s[3]);
-	s[2] = chi(s[2], s[3], s[4]);
-	s[3] = chi(s[3], s[4], u);
-	s[4] = chi(s[4], u, v);
-
-	u = s[5]; v = s[6];
-	s[5] = chi(s[5], s[6], s[7]);
-	s[6] = chi(s[6], s[7], s[8]);
-	s[7] = chi(s[7], s[8], s[9]);
-	s[8] = chi(s[8], s[9], u);
-	s[9] = chi(s[9], u, v);
-
-	u = s[10]; v = s[11];
-	s[10] = chi(s[10], s[11], s[12]);
-	s[11] = chi(s[11], s[12], s[13]);
-	s[12] = chi(s[12], s[13], s[14]);
-	s[13] = chi(s[13], s[14], u);
-	s[14] = chi(s[14], u, v);
-
-	u = s[15]; v = s[16];
-	s[15] = chi(s[15], s[16], s[17]);
-	s[16] = chi(s[16], s[17], s[18]);
-	s[17] = chi(s[17], s[18], s[19]);
-	s[18] = chi(s[18], s[19], u);
-	s[19] = chi(s[19], u, v);
-
-	u = s[20]; v = s[21];
-	s[20] = chi(s[20], s[21], s[22]);
-	s[21] = chi(s[21], s[22], s[23]);
-	s[22] = chi(s[22], s[23], s[24]);
-	s[23] = chi(s[23], s[24], u);
-	s[24] = chi(s[24], u, v);
-
-	/* iota: a[0,0] ^= round constant */
-	s[0] ^= vectorize(keccak_round_constants[0]);
-
-	for (int i = 1; i < 23; i++)
-	{
-		/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
-		t[0] = xor5(s[0] , s[5] , s[10] , s[15] , s[20]);
-		t[1] = xor5(s[1] , s[6] , s[11] , s[16] , s[21]);
-		t[2] = xor5(s[2] , s[7] , s[12] , s[17] , s[22]);
-		t[3] = xor5(s[3] , s[8] , s[13] , s[18] , s[23]);
-		t[4] = xor5(s[4] , s[9] , s[14] , s[19] , s[24]);
-
-		/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
-		/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
-
-		u = ROL2(t[1], 1);
-		s[0]  = xor3(s[0], t[4], u);
-		s[5]  = xor3(s[5], t[4], u);
-		s[10] = xor3(s[10], t[4], u);
-		s[15] = xor3(s[15], t[4], u);
-		s[20] = xor3(s[20], t[4], u);
-
-		u = ROL2(t[2], 1);
-		s[1] = xor3(s[1], t[0], u);
-		s[6] = xor3(s[6], t[0], u);
-		s[11] = xor3(s[11], t[0], u);
-		s[16] = xor3(s[16], t[0], u);
-		s[21] = xor3(s[21], t[0], u);
-
-		u = ROL2(t[3], 1);
-		s[2] = xor3(s[2], t[1], u);
-		s[7] = xor3(s[7], t[1], u);
-		s[12] = xor3(s[12], t[1], u);
-		s[17] = xor3(s[17], t[1], u);
-		s[22] = xor3(s[22], t[1], u);
-
-		u = ROL2(t[4], 1);
-		s[3] = xor3(s[3], t[2], u);
-		s[8] = xor3(s[8], t[2], u);
-		s[13] = xor3(s[13], t[2], u);
-		s[18] = xor3(s[18], t[2], u);
-		s[23] = xor3(s[23], t[2], u);
-
-
-		u = ROL2(t[0], 1);
-		s[4] = xor3(s[4], t[3], u);
-		s[9] = xor3(s[9], t[3], u);
-		s[14] = xor3(s[14], t[3], u);
-		s[19] = xor3(s[19], t[3], u);
-		s[24] = xor3(s[24], t[3], u);
-
-		/* rho pi: b[..] = rotl(a[..], ..) */
-		u = s[1];
-
-		s[1] = ROL2(s[6], 44);
-		s[6] = ROL2(s[9], 20);
-		s[9] = ROL2(s[22], 61);
-		s[22] = ROL2(s[14], 39);
-		s[14] = ROL2(s[20], 18);
-		s[20] = ROL2(s[2], 62);
-		s[2] = ROL2(s[12], 43);
-		s[12] = ROL2(s[13], 25);
-		s[13] = ROL2(s[19], 8);
-		s[19] = ROL2(s[23], 56);
-		s[23] = ROL2(s[15], 41);
-		s[15] = ROL2(s[4], 27);
-		s[4] = ROL2(s[24], 14);
-		s[24] = ROL2(s[21], 2);
-		s[21] = ROL2(s[8], 55);
-		s[8] = ROL2(s[16], 45);
-		s[16] = ROL2(s[5], 36);
-		s[5] = ROL2(s[3], 28);
-		s[3] = ROL2(s[18], 21);
-		s[18] = ROL2(s[17], 15);
-		s[17] = ROL2(s[11], 10);
-		s[11] = ROL2(s[7], 6);
-		s[7] = ROL2(s[10], 3);
-		s[10] = ROL2(u, 1);
-
-		/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
-			
-		u = s[0]; v = s[1];
-		s[0] = chi(s[0], s[1], s[2]);
-		s[1] = chi(s[1], s[2], s[3]);
-		s[2] = chi(s[2], s[3], s[4]);
-		s[3] = chi(s[3], s[4], u);
-		s[4] = chi(s[4], u, v);
-
-		u = s[5]; v = s[6]; 
-		s[5] = chi(s[5], s[6], s[7]);
-		s[6] = chi(s[6], s[7], s[8]);
-		s[7] = chi(s[7], s[8], s[9]);
-		s[8] = chi(s[8], s[9], u);
-		s[9] = chi(s[9], u, v);
-
-		u = s[10]; v = s[11]; 
-		s[10] = chi(s[10], s[11], s[12]);
-		s[11] = chi(s[11], s[12], s[13]);
-		s[12] = chi(s[12], s[13], s[14]);
-		s[13] = chi(s[13], s[14], u);
-		s[14] = chi(s[14], u, v);
-
-		u = s[15]; v = s[16];
-		s[15] = chi(s[15], s[16], s[17]);
-		s[16] = chi(s[16], s[17], s[18]);
-		s[17] = chi(s[17], s[18], s[19]);
-		s[18] = chi(s[18], s[19], u);
-		s[19] = chi(s[19], u, v);
-
-		u = s[20]; v = s[21];
-		s[20] = chi(s[20], s[21], s[22]);
-		s[21] = chi(s[21], s[22], s[23]);
-		s[22] = chi(s[22], s[23], s[24]);
-		s[23] = chi(s[23], s[24], u);
-		s[24] = chi(s[24], u, v);
-
-		/* iota: a[0,0] ^= round constant */
-		s[0] ^= vectorize(keccak_round_constants[i]);
-	}
-
-	/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
-	t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
-	t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
-	t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
-	t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
-	t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
-
-	/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
-	/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
-
-	u = ROL2(t[1], 1);
-	s[0] = xor3(s[0], t[4], u);
-	s[10] = xor3(s[10], t[4], u);
-
-	u = ROL2(t[2], 1);
-	s[6] = xor3(s[6], t[0], u);
-	s[16] = xor3(s[16], t[0], u);
-
-	u = ROL2(t[3], 1);
-	s[12] = xor3(s[12], t[1], u);
-	s[22] = xor3(s[22], t[1], u);
-
-	u = ROL2(t[4], 1);
-	s[3] = xor3(s[3], t[2], u);
-	s[18] = xor3(s[18], t[2], u);
-
-	u = ROL2(t[0], 1);
-	s[9] = xor3(s[9], t[3], u);
-	s[24] = xor3(s[24], t[3], u);
-
-	/* rho pi: b[..] = rotl(a[..], ..) */
-	u = s[1];
-
-	s[1] = ROL2(s[6], 44);
-	s[6] = ROL2(s[9], 20);
-	s[9] = ROL2(s[22], 61);
-	s[2] = ROL2(s[12], 43);
-	s[4] = ROL2(s[24], 14);
-	s[8] = ROL2(s[16], 45);
-	s[5] = ROL2(s[3], 28);
-	s[3] = ROL2(s[18], 21);
-	s[7] = ROL2(s[10], 3);
-
-	/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
-
-	u = s[0]; v = s[1];
-	s[0] = chi(s[0], s[1], s[2]);
-	s[1] = chi(s[1], s[2], s[3]);
-	s[2] = chi(s[2], s[3], s[4]);
-	s[3] = chi(s[3], s[4], u);
-	s[4] = chi(s[4], u, v);
-	s[5] = chi(s[5], s[6], s[7]);
-	s[6] = chi(s[6], s[7], s[8]);
-	s[7] = chi(s[7], s[8], s[9]);
-
-	/* iota: a[0,0] ^= round constant */
-	s[0] ^= vectorize(keccak_round_constants[23]);
-
-	for(int i = 0; i < 12; ++i)
-	    state[i] = s[i];
-}
-
-__device__ __forceinline__ uint64_t keccak_f1600_final(uint2* state)
-{
-	uint2 s[25];
-	uint2 t[5], u, v;
-
-	for (int i = 0; i < 12; ++i)
-		s[i] = state[i];
-
-	for (uint32_t i = 12; i < 25; i++)
-	{
-		s[i] = make_uint2(0, 0);
-	}
-	s[12].x = 1;
-	s[16].y = 0x80000000;
-	
-	/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
-	t[0] = xor3(s[0], s[5], s[10]);
-	t[1] = xor3(s[1], s[6], s[11]) ^ s[16];
-	t[2] = xor3(s[2], s[7], s[12]);
-	t[3] = s[3] ^ s[8];
-	t[4] = s[4] ^ s[9];
-
-	/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
-	/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
-
-	u = ROL2(t[1], 1);
-	s[0] = xor3(s[0], t[4], u);
-	s[5] = xor3(s[5], t[4], u);
-	s[10] = xor3(s[10], t[4], u);
-	s[15] = xor3(s[15], t[4], u);
-	s[20] = xor3(s[20], t[4], u);
-
-	u = ROL2(t[2], 1);
-	s[1] = xor3(s[1], t[0], u);
-	s[6] = xor3(s[6], t[0], u);
-	s[11] = xor3(s[11], t[0], u);
-	s[16] = xor3(s[16], t[0], u);
-	s[21] = xor3(s[21], t[0], u);
-
-	u = ROL2(t[3], 1);
-	s[2] = xor3(s[2], t[1], u);
-	s[7] = xor3(s[7], t[1], u);
-	s[12] = xor3(s[12], t[1], u);
-	s[17] = xor3(s[17], t[1], u);
-	s[22] = xor3(s[22], t[1], u);
-
-	u = ROL2(t[4], 1);
-	s[3] = xor3(s[3], t[2], u);
-	s[8] = xor3(s[8], t[2], u);
-	s[13] = xor3(s[13], t[2], u);
-	s[18] = xor3(s[18], t[2], u);
-	s[23] = xor3(s[23], t[2], u);
-
-
-	u = ROL2(t[0], 1);
-	s[4] = xor3(s[4], t[3], u);
-	s[9] = xor3(s[9], t[3], u);
-	s[14] = xor3(s[14], t[3], u);
-	s[19] = xor3(s[19], t[3], u);
-	s[24] = xor3(s[24], t[3], u);
-
-	/* rho pi: b[..] = rotl(a[..], ..) */
-	u = s[1];
-
-	s[1] = ROL2(s[6], 44);
-	s[6] = ROL2(s[9], 20);
-	s[9] = ROL2(s[22], 61);
-	s[22] = ROL2(s[14], 39);
-	s[14] = ROL2(s[20], 18);
-	s[20] = ROL2(s[2], 62);
-	s[2] = ROL2(s[12], 43);
-	s[12] = ROL2(s[13], 25);
-	s[13] = ROL2(s[19], 8);
-	s[19] = ROL2(s[23], 56);
-	s[23] = ROL2(s[15], 41);
-	s[15] = ROL2(s[4], 27);
-	s[4] = ROL2(s[24], 14);
-	s[24] = ROL2(s[21], 2);
-	s[21] = ROL2(s[8], 55);
-	s[8] = ROL2(s[16], 45);
-	s[16] = ROL2(s[5], 36);
-	s[5] = ROL2(s[3], 28);
-	s[3] = ROL2(s[18], 21);
-	s[18] = ROL2(s[17], 15);
-	s[17] = ROL2(s[11], 10);
-	s[11] = ROL2(s[7], 6);
-	s[7] = ROL2(s[10], 3);
-	s[10] = ROL2(u, 1);
-
-	/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
-	u = s[0]; v = s[1];
-	s[0] = chi(s[0], s[1], s[2]);
-	s[1] = chi(s[1], s[2], s[3]);
-	s[2] = chi(s[2], s[3], s[4]);
-	s[3] = chi(s[3], s[4], u);
-	s[4] = chi(s[4], u, v);
-
-	u = s[5]; v = s[6];
-	s[5] = chi(s[5], s[6], s[7]);
-	s[6] = chi(s[6], s[7], s[8]);
-	s[7] = chi(s[7], s[8], s[9]);
-	s[8] = chi(s[8], s[9], u);
-	s[9] = chi(s[9], u, v);
-
-	u = s[10]; v = s[11];
-	s[10] = chi(s[10], s[11], s[12]);
-	s[11] = chi(s[11], s[12], s[13]);
-	s[12] = chi(s[12], s[13], s[14]);
-	s[13] = chi(s[13], s[14], u);
-	s[14] = chi(s[14], u, v);
-
-	u = s[15]; v = s[16];
-	s[15] = chi(s[15], s[16], s[17]);
-	s[16] = chi(s[16], s[17], s[18]);
-	s[17] = chi(s[17], s[18], s[19]);
-	s[18] = chi(s[18], s[19], u);
-	s[19] = chi(s[19], u, v);
-
-	u = s[20]; v = s[21];
-	s[20] = chi(s[20], s[21], s[22]);
-	s[21] = chi(s[21], s[22], s[23]);
-	s[22] = chi(s[22], s[23], s[24]);
-	s[23] = chi(s[23], s[24], u);
-	s[24] = chi(s[24], u, v);
-
-	/* iota: a[0,0] ^= round constant */
-	s[0] ^= vectorize(keccak_round_constants[0]);
-
-	for (int i = 1; i < 23; i++)
-	{
-		/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
-		t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
-		t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
-		t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
-		t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
-		t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
-
-		/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
-		/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
-
-		u = ROL2(t[1], 1);
-		s[0] = xor3(s[0], t[4], u);
-		s[5] = xor3(s[5], t[4], u);
-		s[10] = xor3(s[10], t[4], u);
-		s[15] = xor3(s[15], t[4], u);
-		s[20] = xor3(s[20], t[4], u);
-
-		u = ROL2(t[2], 1);
-		s[1] = xor3(s[1], t[0], u);
-		s[6] = xor3(s[6], t[0], u);
-		s[11] = xor3(s[11], t[0], u);
-		s[16] = xor3(s[16], t[0], u);
-		s[21] = xor3(s[21], t[0], u);
-
-		u = ROL2(t[3], 1);
-		s[2] = xor3(s[2], t[1], u);
-		s[7] = xor3(s[7], t[1], u);
-		s[12] = xor3(s[12], t[1], u);
-		s[17] = xor3(s[17], t[1], u);
-		s[22] = xor3(s[22], t[1], u);
-
-		u = ROL2(t[4], 1);
-		s[3] = xor3(s[3], t[2], u);
-		s[8] = xor3(s[8], t[2], u);
-		s[13] = xor3(s[13], t[2], u);
-		s[18] = xor3(s[18], t[2], u);
-		s[23] = xor3(s[23], t[2], u);
-
-
-		u = ROL2(t[0], 1);
-		s[4] = xor3(s[4], t[3], u);
-		s[9] = xor3(s[9], t[3], u);
-		s[14] = xor3(s[14], t[3], u);
-		s[19] = xor3(s[19], t[3], u);
-		s[24] = xor3(s[24], t[3], u);
-
-		/* rho pi: b[..] = rotl(a[..], ..) */
-		u = s[1];
-
-		s[1] = ROL2(s[6], 44);
-		s[6] = ROL2(s[9], 20);
-		s[9] = ROL2(s[22], 61);
-		s[22] = ROL2(s[14], 39);
-		s[14] = ROL2(s[20], 18);
-		s[20] = ROL2(s[2], 62);
-		s[2] = ROL2(s[12], 43);
-		s[12] = ROL2(s[13], 25);
-		s[13] = ROL2(s[19], 8);
-		s[19] = ROL2(s[23], 56);
-		s[23] = ROL2(s[15], 41);
-		s[15] = ROL2(s[4], 27);
-		s[4] = ROL2(s[24], 14);
-		s[24] = ROL2(s[21], 2);
-		s[21] = ROL2(s[8], 55);
-		s[8] = ROL2(s[16], 45);
-		s[16] = ROL2(s[5], 36);
-		s[5] = ROL2(s[3], 28);
-		s[3] = ROL2(s[18], 21);
-		s[18] = ROL2(s[17], 15);
-		s[17] = ROL2(s[11], 10);
-		s[11] = ROL2(s[7], 6);
-		s[7] = ROL2(s[10], 3);
-		s[10] = ROL2(u, 1);
-
-		/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
-		u = s[0]; v = s[1];
-		s[0] = chi(s[0], s[1], s[2]);	
-		s[1] = chi(s[1], s[2], s[3]);
-		s[2] = chi(s[2], s[3], s[4]);
-		s[3] = chi(s[3], s[4], u);
-		s[4] = chi(s[4], u, v);
-
-		u = s[5]; v = s[6];
-		s[5] = chi(s[5], s[6], s[7]);
-		s[6] = chi(s[6], s[7], s[8]);
-		s[7] = chi(s[7], s[8], s[9]);
-		s[8] = chi(s[8], s[9], u);
-		s[9] = chi(s[9], u, v);
-
-		u = s[10]; v = s[11];
-		s[10] = chi(s[10], s[11], s[12]);
-		s[11] = chi(s[11], s[12], s[13]);
-		s[12] = chi(s[12], s[13], s[14]);
-		s[13] = chi(s[13], s[14], u);
-		s[14] = chi(s[14], u, v);
-
-		u = s[15]; v = s[16];
-		s[15] = chi(s[15], s[16], s[17]);
-		s[16] = chi(s[16], s[17], s[18]);
-		s[17] = chi(s[17], s[18], s[19]);
-		s[18] = chi(s[18], s[19], u);
-		s[19] = chi(s[19], u, v);
-
-		u = s[20]; v = s[21];
-		s[20] = chi(s[20], s[21], s[22]);
-		s[21] = chi(s[21], s[22], s[23]);
-		s[22] = chi(s[22], s[23], s[24]);
-		s[23] = chi(s[23], s[24], u);
-		s[24] = chi(s[24], u, v);
-
-		/* iota: a[0,0] ^= round constant */
-		s[0] ^= vectorize(keccak_round_constants[i]);
-	}
-
-	t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
-	t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
-	t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
-	t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
-	t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
-
-	s[0] = xor3(s[0], t[4], ROL2(t[1], 1));
-	s[6] = xor3(s[6], t[0], ROL2(t[2], 1));
-	s[12] = xor3(s[12], t[1], ROL2(t[3], 1));
-
-	s[1] = ROL2(s[6], 44);
-	s[2] = ROL2(s[12], 43);
-
-	s[0] = chi(s[0], s[1], s[2]);
-
-	/* iota: a[0,0] ^= round constant */
-	//s[0] ^= vectorize(keccak_round_constants[23]);
-	return devectorize(s[0]) ^ keccak_round_constants[23];
-}
-
-__device__ __forceinline__ void SHA3_512(uint2* s) {
-	
-	uint2 t[5], u, v;
-
-	for (uint32_t i = 8; i < 25; i++)
-	{
-		s[i] = make_uint2(0, 0);
-	}
-	s[8].x = 1;
-	s[8].y = 0x80000000;
-
-	for (int i = 0; i < 23; i++)
-	{
-		/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
-		t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
-		t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
-		t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
-		t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
-		t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
-
-		/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
-		/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
-
-		u = ROL2(t[1], 1);
-		s[0] = xor3(s[0], t[4], u);
-		s[5] = xor3(s[5], t[4], u);
-		s[10] = xor3(s[10], t[4], u);
-		s[15] = xor3(s[15], t[4], u);
-		s[20] = xor3(s[20], t[4], u);
-
-		u = ROL2(t[2], 1);
-		s[1] = xor3(s[1], t[0], u);
-		s[6] = xor3(s[6], t[0], u);
-		s[11] = xor3(s[11], t[0], u);
-		s[16] = xor3(s[16], t[0], u);
-		s[21] = xor3(s[21], t[0], u);
-
-		u = ROL2(t[3], 1);
-		s[2] = xor3(s[2], t[1], u);
-		s[7] = xor3(s[7], t[1], u);
-		s[12] = xor3(s[12], t[1], u);
-		s[17] = xor3(s[17], t[1], u);
-		s[22] = xor3(s[22], t[1], u);
-
-		u = ROL2(t[4], 1);
-		s[3] = xor3(s[3], t[2], u);
-		s[8] = xor3(s[8], t[2], u);
-		s[13] = xor3(s[13], t[2], u);
-		s[18] = xor3(s[18], t[2], u);
-		s[23] = xor3(s[23], t[2], u);
-
-
-		u = ROL2(t[0], 1);
-		s[4] = xor3(s[4], t[3], u);
-		s[9] = xor3(s[9], t[3], u);
-		s[14] = xor3(s[14], t[3], u);
-		s[19] = xor3(s[19], t[3], u);
-		s[24] = xor3(s[24], t[3], u);
-
-		/* rho pi: b[..] = rotl(a[..], ..) */
-		u = s[1];
-
-		s[1] = ROL2(s[6], 44);
-		s[6] = ROL2(s[9], 20);
-		s[9] = ROL2(s[22], 61);
-		s[22] = ROL2(s[14], 39);
-		s[14] = ROL2(s[20], 18);
-		s[20] = ROL2(s[2], 62);
-		s[2] = ROL2(s[12], 43);
-		s[12] = ROL2(s[13], 25);
-		s[13] = ROL2(s[19], 8);
-		s[19] = ROL2(s[23], 56);
-		s[23] = ROL2(s[15], 41);
-		s[15] = ROL2(s[4], 27);
-		s[4] = ROL2(s[24], 14);
-		s[24] = ROL2(s[21], 2);
-		s[21] = ROL2(s[8], 55);
-		s[8] = ROL2(s[16], 45);
-		s[16] = ROL2(s[5], 36);
-		s[5] = ROL2(s[3], 28);
-		s[3] = ROL2(s[18], 21);
-		s[18] = ROL2(s[17], 15);
-		s[17] = ROL2(s[11], 10);
-		s[11] = ROL2(s[7], 6);
-		s[7] = ROL2(s[10], 3);
-		s[10] = ROL2(u, 1);
-
-		/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
-		u = s[0]; v = s[1];
-		s[0] = chi(s[0], s[1], s[2]);
-		s[1] = chi(s[1], s[2], s[3]);
-		s[2] = chi(s[2], s[3], s[4]);
-		s[3] = chi(s[3], s[4], u);
-		s[4] = chi(s[4], u, v);
-
-		u = s[5]; v = s[6];
-		s[5] = chi(s[5], s[6], s[7]);
-		s[6] = chi(s[6], s[7], s[8]);
-		s[7] = chi(s[7], s[8], s[9]);
-		s[8] = chi(s[8], s[9], u);
-		s[9] = chi(s[9], u, v);
-
-		u = s[10]; v = s[11];
-		s[10] = chi(s[10], s[11], s[12]);
-		s[11] = chi(s[11], s[12], s[13]);
-		s[12] = chi(s[12], s[13], s[14]);
-		s[13] = chi(s[13], s[14], u);
-		s[14] = chi(s[14], u, v);
-
-		u = s[15]; v = s[16];
-		s[15] = chi(s[15], s[16], s[17]);
-		s[16] = chi(s[16], s[17], s[18]);
-		s[17] = chi(s[17], s[18], s[19]);
-		s[18] = chi(s[18], s[19], u);
-		s[19] = chi(s[19], u, v);
-
-		u = s[20]; v = s[21];
-		s[20] = chi(s[20], s[21], s[22]);
-		s[21] = chi(s[21], s[22], s[23]);
-		s[22] = chi(s[22], s[23], s[24]);
-		s[23] = chi(s[23], s[24], u);
-		s[24] = chi(s[24], u, v);
-
-		/* iota: a[0,0] ^= round constant */
-		s[0] ^= vectorize(keccak_round_constants[i]);
-	}
-
-	/* theta: c = a[0,i] ^ a[1,i] ^ .. a[4,i] */
-	t[0] = xor5(s[0], s[5], s[10], s[15], s[20]);
-	t[1] = xor5(s[1], s[6], s[11], s[16], s[21]);
-	t[2] = xor5(s[2], s[7], s[12], s[17], s[22]);
-	t[3] = xor5(s[3], s[8], s[13], s[18], s[23]);
-	t[4] = xor5(s[4], s[9], s[14], s[19], s[24]);
-
-	/* theta: d[i] = c[i+4] ^ rotl(c[i+1],1) */
-	/* theta: a[0,i], a[1,i], .. a[4,i] ^= d[i] */
-
-	u = ROL2(t[1], 1);
-	s[0] = xor3(s[0], t[4], u);
-	s[10] = xor3(s[10], t[4], u);
-
-	u = ROL2(t[2], 1);
-	s[6] = xor3(s[6], t[0], u);
-	s[16] = xor3(s[16], t[0], u);
-
-	u = ROL2(t[3], 1);
-	s[12] = xor3(s[12], t[1], u);
-	s[22] = xor3(s[22], t[1], u);
-
-	u = ROL2(t[4], 1);
-	s[3] = xor3(s[3], t[2], u);
-	s[18] = xor3(s[18], t[2], u);
-
-	u = ROL2(t[0], 1);
-	s[9] = xor3(s[9], t[3], u);
-	s[24] = xor3(s[24], t[3], u);
-
-	/* rho pi: b[..] = rotl(a[..], ..) */
-	u = s[1];
-
-	s[1] = ROL2(s[6], 44);
-	s[6] = ROL2(s[9], 20);
-	s[9] = ROL2(s[22], 61);
-	s[2] = ROL2(s[12], 43);
-	s[4] = ROL2(s[24], 14);
-	s[8] = ROL2(s[16], 45);
-	s[5] = ROL2(s[3], 28);
-	s[3] = ROL2(s[18], 21);
-	s[7] = ROL2(s[10], 3);
-
-	/* chi: a[i,j] ^= ~b[i,j+1] & b[i,j+2] */
-
-	u = s[0]; v = s[1];
-	s[0] = chi(s[0], s[1], s[2]);
-	s[1] = chi(s[1], s[2], s[3]);
-	s[2] = chi(s[2], s[3], s[4]);
-	s[3] = chi(s[3], s[4], u);
-	s[4] = chi(s[4], u, v);
-	s[5] = chi(s[5], s[6], s[7]);
-	s[6] = chi(s[6], s[7], s[8]);
-	s[7] = chi(s[7], s[8], s[9]);
-
-	/* iota: a[0,0] ^= round constant */
-	s[0] ^= vectorize(keccak_round_constants[23]);
-}
diff --git a/libethash-cuda/dagger_shuffled.cuh b/libethash-cuda/dagger_shuffled.cuh
index b3a443d23a..9d5754585a 100644
--- a/libethash-cuda/dagger_shuffled.cuh
+++ b/libethash-cuda/dagger_shuffled.cuh
@@ -2,12 +2,14 @@
 #include "ethash_cuda_miner_kernel.h"
 #include "cuda_helper.h"
 
+#define PARALLEL_HASH 4
+
 __device__ uint64_t compute_hash(
 	uint64_t nonce
 	)
 {
 	// sha3_512(header .. nonce)
-	uint2 state[25];
+	uint2 state[12];
 	
 	state[4] = vectorize(nonce);
 
@@ -17,32 +19,30 @@ __device__ uint64_t compute_hash(
 	const int thread_id  = threadIdx.x &  (THREADS_PER_HASH - 1);
 	const int mix_idx    = thread_id & 3;
 
-	uint4 mix;
-	uint2 shuffle[8];
-	
-	for (int i = 0; i < THREADS_PER_HASH; i++)
+	for (int i = 0; i < THREADS_PER_HASH; i += PARALLEL_HASH)
 	{
+		uint4 mix[PARALLEL_HASH];
+		uint32_t offset[PARALLEL_HASH];
+		uint32_t init0[PARALLEL_HASH];
+	
 		// share init among threads
-		for (int j = 0; j < 8; j++) {
-			shuffle[j].x = __shfl(state[j].x, i, THREADS_PER_HASH);
-			shuffle[j].y = __shfl(state[j].y, i, THREADS_PER_HASH);
-		}
-
-		// ugly but avoids local reads/writes
-		if (mix_idx < 2) {
-			if (mix_idx == 0)
-				mix = vectorize2(shuffle[0], shuffle[1]);
-			else
-				mix = vectorize2(shuffle[2], shuffle[3]);
-		}
-		else  {
-			if (mix_idx == 2)
-				mix = vectorize2(shuffle[4], shuffle[5]);
-			else
-				mix = vectorize2(shuffle[6], shuffle[7]);
+		for (int p = 0; p < PARALLEL_HASH; p++)
+		{
+			uint2 shuffle[8];
+			for (int j = 0; j < 8; j++) 
+			{
+				shuffle[j].x = __shfl(state[j].x, i+p, THREADS_PER_HASH);
+				shuffle[j].y = __shfl(state[j].y, i+p, THREADS_PER_HASH);
+			}
+			switch (mix_idx)
+			{
+				case 0: mix[p] = vectorize2(shuffle[0], shuffle[1]); break;
+				case 1: mix[p] = vectorize2(shuffle[2], shuffle[3]); break;
+				case 2: mix[p] = vectorize2(shuffle[4], shuffle[5]); break;
+				case 3: mix[p] = vectorize2(shuffle[6], shuffle[7]); break;
+			}
+			init0[p] = __shfl(shuffle[0].x, 0, THREADS_PER_HASH);
 		}
-		
-		uint32_t init0 = __shfl(shuffle[0].x, 0, THREADS_PER_HASH);
 
 		for (uint32_t a = 0; a < ACCESSES; a += 4)
 		{
@@ -50,37 +50,45 @@ __device__ uint64_t compute_hash(
 
 			for (uint32_t b = 0; b < 4; b++)
 			{
-				if (thread_id == t)
-				{	
-					shuffle[0].x = fnv(init0 ^ (a + b), ((uint32_t *)&mix)[b]) % d_dag_size;
+				for (int p = 0; p < PARALLEL_HASH; p++)
+				{
+					offset[p] = fnv(init0[p] ^ (a + b), ((uint32_t *)&mix[p])[b]) % d_dag_size;
+					offset[p] = __shfl(offset[p], t, THREADS_PER_HASH);
+				}
+				#pragma unroll
+				for (int p = 0; p < PARALLEL_HASH; p++)
+				{
+					mix[p] = fnv4(mix[p], d_dag[offset[p]].uint4s[thread_id]);
 				}
-				shuffle[0].x = __shfl(shuffle[0].x, t, THREADS_PER_HASH);
-				mix = fnv4(mix, d_dag[shuffle[0].x].uint4s[thread_id]);
 			}
 		}
 
-		uint32_t thread_mix = fnv_reduce(mix);
+		for (int p = 0; p < PARALLEL_HASH; p++)
+		{
+			uint2 shuffle[4];
+			uint32_t thread_mix = fnv_reduce(mix[p]);
+
+			// update mix accross threads
 
-		// update mix accross threads
-		
-		shuffle[0].x = __shfl(thread_mix, 0, THREADS_PER_HASH);
-		shuffle[0].y = __shfl(thread_mix, 1, THREADS_PER_HASH);
-		shuffle[1].x = __shfl(thread_mix, 2, THREADS_PER_HASH);
-		shuffle[1].y = __shfl(thread_mix, 3, THREADS_PER_HASH);
-		shuffle[2].x = __shfl(thread_mix, 4, THREADS_PER_HASH);
-		shuffle[2].y = __shfl(thread_mix, 5, THREADS_PER_HASH);
-		shuffle[3].x = __shfl(thread_mix, 6, THREADS_PER_HASH);
-		shuffle[3].y = __shfl(thread_mix, 7, THREADS_PER_HASH);
-		
-		if (i == thread_id) {
-			//move mix into state:
-			state[8] = shuffle[0];
-			state[9] = shuffle[1];
-			state[10] = shuffle[2];
-			state[11] = shuffle[3];
+			shuffle[0].x = __shfl(thread_mix, 0, THREADS_PER_HASH);
+			shuffle[0].y = __shfl(thread_mix, 1, THREADS_PER_HASH);
+			shuffle[1].x = __shfl(thread_mix, 2, THREADS_PER_HASH);
+			shuffle[1].y = __shfl(thread_mix, 3, THREADS_PER_HASH);
+			shuffle[2].x = __shfl(thread_mix, 4, THREADS_PER_HASH);
+			shuffle[2].y = __shfl(thread_mix, 5, THREADS_PER_HASH);
+			shuffle[3].x = __shfl(thread_mix, 6, THREADS_PER_HASH);
+			shuffle[3].y = __shfl(thread_mix, 7, THREADS_PER_HASH);
+
+			if ((i+p) == thread_id) {
+				//move mix into state:
+				state[8] = shuffle[0];
+				state[9] = shuffle[1];
+				state[10] = shuffle[2];
+				state[11] = shuffle[3];
+			}
 		}
 	}
 	
 	// keccak_256(keccak_512(header..nonce) .. mix);
 	return keccak_f1600_final(state);
-}
\ No newline at end of file
+}
diff --git a/libethash-cuda/ethash_cuda_miner_kernel.cu b/libethash-cuda/ethash_cuda_miner_kernel.cu
index e162396994..ac607c3a20 100644
--- a/libethash-cuda/ethash_cuda_miner_kernel.cu
+++ b/libethash-cuda/ethash_cuda_miner_kernel.cu
@@ -16,17 +16,12 @@
 #if __CUDA_ARCH__ < SHUFFLE_MIN_VER
 #include "keccak_u64.cuh"
 #include "dagger_shared.cuh"
-#define TPB		128
-#define BPSM	4
 #else
 #include "keccak.cuh"
 #include "dagger_shuffled.cuh"
-#define TPB		896
-#define BPSM	1
 #endif
 
 __global__ void 
-__launch_bounds__(TPB, BPSM)
 ethash_search(
 	volatile uint32_t* g_output,
 	uint64_t start_nonce
@@ -56,7 +51,6 @@ void run_ethash_search(
 #define NODE_WORDS (64/4)
 
 __global__ void
-__launch_bounds__(128, 7)
 ethash_calculate_dag_item(uint32_t start)
 {
 	uint32_t const node_index = start + blockIdx.x * blockDim.x + threadIdx.x;
diff --git a/libethash-cuda/keccak.cuh b/libethash-cuda/keccak.cuh
index 86969e014d..ede8ecf54e 100644
--- a/libethash-cuda/keccak.cuh
+++ b/libethash-cuda/keccak.cuh
@@ -25,10 +25,13 @@ uint2 chi(const uint2 a, const uint2 b, const uint2 c) {
 	return a ^ (~b) & c;
 }
 
-__device__ __forceinline__ void keccak_f1600_init(uint2* s)
+__device__ __forceinline__ void keccak_f1600_init(uint2* state)
 {
+	uint2 s[25];
 	uint2 t[5], u, v;
 
+	s[4] = state[4];
+
 	devectorize2(d_header.uint4s[0], s[0], s[1]);
 	devectorize2(d_header.uint4s[1], s[2], s[3]);
 
@@ -328,12 +331,19 @@ __device__ __forceinline__ void keccak_f1600_init(uint2* s)
 
 	/* iota: a[0,0] ^= round constant */
 	s[0] ^= vectorize(keccak_round_constants[23]);
+
+	for(int i = 0; i < 12; ++i)
+	    state[i] = s[i];
 }
 
-__device__ __forceinline__ uint64_t keccak_f1600_final(uint2* s)
+__device__ __forceinline__ uint64_t keccak_f1600_final(uint2* state)
 {
+	uint2 s[25];
 	uint2 t[5], u, v;
 
+	for (int i = 0; i < 12; ++i)
+		s[i] = state[i];
+
 	for (uint32_t i = 12; i < 25; i++)
 	{
 		s[i] = make_uint2(0, 0);
@@ -774,4 +784,4 @@ __device__ __forceinline__ void SHA3_512(uint2* s) {
 
 	/* iota: a[0,0] ^= round constant */
 	s[0] ^= vectorize(keccak_round_constants[23]);
-}
\ No newline at end of file
+}
